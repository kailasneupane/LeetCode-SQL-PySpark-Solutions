{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1378. Replace Employee ID With The Unique Identifier](https://leetcode.com/problems/replace-employee-id-with-the-unique-identifier/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2ef0c272e6c920"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Employees\n",
    "<pre>\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| name          | varchar |\n",
    "+---------------+---------+</pre>\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table contains the id and the name of an employee in a company.\n",
    " \n",
    "\n",
    "Table: EmployeeUNI\n",
    "<pre>\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| unique_id     | int     |\n",
    "+---------------+---------+</pre>\n",
    "(id, unique_id) is the primary key (combination of columns with unique values) for this table.\n",
    "Each row of this table contains the id and the corresponding unique id of an employee in the company.\n",
    " \n",
    "\n",
    "Write a solution to show the unique ID of each user, If a user does not have a unique ID replace just show null.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employees table:\n",
    "<pre>+----+----------+\n",
    "| id | name     |\n",
    "+----+----------+\n",
    "| 1  | Alice    |\n",
    "| 7  | Bob      |\n",
    "| 11 | Meir     |\n",
    "| 90 | Winston  |\n",
    "| 3  | Jonathan |\n",
    "+----+----------+</pre>\n",
    "EmployeeUNI table:\n",
    "<pre>+----+-----------+\n",
    "| id | unique_id |\n",
    "+----+-----------+\n",
    "| 3  | 1         |\n",
    "| 11 | 2         |\n",
    "| 90 | 3         |\n",
    "+----+-----------+</pre>\n",
    "Output: \n",
    "<pre>+-----------+----------+\n",
    "| unique_id | name     |\n",
    "+-----------+----------+\n",
    "| null      | Alice    |\n",
    "| null      | Bob      |\n",
    "| 2         | Meir     |\n",
    "| 3         | Winston  |\n",
    "| 1         | Jonathan |\n",
    "+-----------+----------+</pre>\n",
    "Explanation: \n",
    "Alice and Bob do not have a unique ID, We will show null instead.\n",
    "The unique ID of Meir is 2.\n",
    "The unique ID of Winston is 3.\n",
    "The unique ID of Jonathan is 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8833a5b06fff9667"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Pandas Schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 'Alice'], [7, 'Bob'], [11, 'Meir'], [90, 'Winston'], [3, 'Jonathan']]\n",
    "employees = pd.DataFrame(data, columns=['id', 'name']).astype({'id':'int64', 'name':'object'})\n",
    "data = [[3, 1], [11, 2], [90, 3]]\n",
    "employee_uni = pd.DataFrame(data, columns=['id', 'unique_id']).astype({'id':'int64', 'unique_id':'int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:55:50.805514300Z",
     "start_time": "2023-11-05T18:55:50.263464800Z"
    }
   },
   "id": "9858a8e925b70a5a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:01:05 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:01:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:01:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|id |name    |\n",
      "+---+--------+\n",
      "|1  |Alice   |\n",
      "|7  |Bob     |\n",
      "|11 |Meir    |\n",
      "|90 |Winston |\n",
      "|3  |Jonathan|\n",
      "+---+--------+\n"
     ]
    }
   ],
   "source": [
    "#to pyspark schema\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employees_df = spark.createDataFrame(employees)\n",
    "employees_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:08.274792400Z",
     "start_time": "2023-11-05T18:55:50.811021500Z"
    }
   },
   "id": "54538ea9e380a87e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|id |unique_id|\n",
      "+---+---------+\n",
      "|3  |1        |\n",
      "|11 |2        |\n",
      "|90 |3        |\n",
      "+---+---------+\n"
     ]
    }
   ],
   "source": [
    "employee_uni_df = spark.createDataFrame(employee_uni)\n",
    "employee_uni_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:09.473630200Z",
     "start_time": "2023-11-05T18:56:08.262775700Z"
    }
   },
   "id": "176a4a8e320f176e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     null|   Alice|\n",
      "|     null|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "# in spark Dafaframe\n",
    "\n",
    "employees_df\\\n",
    "    .join(employee_uni_df,on=['id'],how='left')\\\n",
    "    .select('unique_id','name')\\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:11.918252300Z",
     "start_time": "2023-11-05T18:56:09.468227100Z"
    }
   },
   "id": "7c265c30edfbf76a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:=============================================>          (13 + 3) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     null|   Alice|\n",
      "|     null|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# in spark SQL\n",
    "\n",
    "employees_df.createOrReplaceTempView('employees')\n",
    "employee_uni_df.createOrReplaceTempView('employee_uni')\n",
    "\n",
    "spark.sql('''\n",
    "select unique_id, name\n",
    "from employees\n",
    "left join employee_uni \n",
    "on employees.id = employee_uni.id;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:13.707262300Z",
     "start_time": "2023-11-05T18:56:11.922433300Z"
    }
   },
   "id": "89f827a905c69a79"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:14.152656600Z",
     "start_time": "2023-11-05T18:56:13.453788100Z"
    }
   },
   "id": "6f51ccc802d24c64"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:56:14.207768800Z",
     "start_time": "2023-11-05T18:56:14.156848200Z"
    }
   },
   "id": "405f83bfcf69bb8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
