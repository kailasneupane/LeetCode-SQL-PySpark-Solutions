{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [550. Game Play Analysis IV](https://leetcode.com/problems/game-play-analysis-iv/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0b2af75d92d496f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Activity\n",
    "\n",
    "<pre>+--------------+---------+\n",
    "| Column Name  | Type    |\n",
    "+--------------+---------+\n",
    "| player_id    | int     |\n",
    "| device_id    | int     |\n",
    "| event_date   | date    |\n",
    "| games_played | int     |\n",
    "+--------------+---------+</pre>\n",
    "(player_id, event_date) is the primary key (combination of columns with unique values) of this table.\n",
    "This table shows the activity of players of some games.\n",
    "Each row is a record of a player who logged in and played a number of games (possibly 0) before logging out on someday using some device.\n",
    " \n",
    "\n",
    "Write a solution to report the fraction of players that logged in again on the day after the day they first logged in, rounded to 2 decimal places. In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, then divide that number by the total number of players.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "<pre>+-----------+-----------+------------+--------------+\n",
    "| player_id | device_id | event_date | games_played |\n",
    "+-----------+-----------+------------+--------------+\n",
    "| 1         | 2         | 2016-03-01 | 5            |\n",
    "| 1         | 2         | 2016-03-02 | 6            |\n",
    "| 2         | 3         | 2017-06-25 | 1            |\n",
    "| 3         | 1         | 2016-03-02 | 0            |\n",
    "| 3         | 4         | 2018-07-03 | 5            |\n",
    "+-----------+-----------+------------+--------------+</pre>\n",
    "Output: \n",
    "<pre>+-----------+\n",
    "| fraction  |\n",
    "+-----------+\n",
    "| 0.33      |\n",
    "+-----------+</pre>\n",
    "Explanation: \n",
    "Only the player with id 1 logged back in after the first day he had logged in so the answer is 1/3 = 0.33"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0942a0f4f8a5b71"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#pandas schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 2, '2016-03-01', 5], [1, 2, '2016-03-02', 6], [2, 3, '2017-06-25', 1], [3, 1, '2016-03-02', 0],\n",
    "        [3, 4, '2018-07-03', 5]]\n",
    "activity = pd.DataFrame(data, columns=['player_id', 'device_id', 'event_date', 'games_played']).astype(\n",
    "    {'player_id': 'Int64', 'device_id': 'Int64', 'event_date': 'datetime64[ns]', 'games_played': 'Int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:45:58.284949100Z",
     "start_time": "2023-11-10T04:45:57.892865Z"
    }
   },
   "id": "418d0ae8c4f583d0"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/09 15:36:02 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/09 15:36:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 15:36:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+------------+\n",
      "|player_id|device_id|event_date         |games_played|\n",
      "+---------+---------+-------------------+------------+\n",
      "|1        |2        |2016-03-01 00:00:00|5           |\n",
      "|1        |2        |2016-03-02 00:00:00|6           |\n",
      "|2        |3        |2017-06-25 00:00:00|1           |\n",
      "|3        |1        |2016-03-02 00:00:00|0           |\n",
      "|3        |4        |2018-07-03 00:00:00|5           |\n",
      "+---------+---------+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# to spark dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "activity_df = spark.createDataFrame(activity)\n",
    "activity_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:46:10.315846500Z",
     "start_time": "2023-11-10T04:45:58.283940200Z"
    }
   },
   "id": "496cda88a9816ab0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fraction|\n",
      "+--------+\n",
      "|    0.33|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "# solving in spark dataframe\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "activity_df.withColumn('next_date',\n",
    "                       F.lead('event_date').over(Window.partitionBy('player_id').orderBy('event_date'))\n",
    "                       ) \\\n",
    "    .withColumn('rn', F.row_number().over(Window.partitionBy('player_id').orderBy('event_date'))) \\\n",
    "    .filter(F.col('rn') == 1) \\\n",
    "    .agg(\n",
    "    F.round(\n",
    "        F.sum(F.when(F.datediff(F.col('next_date'), F.col('event_date')) == 1, 1).otherwise(0)) / F.count('player_id')\n",
    "        , 2).alias('fraction')\n",
    ") \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:46:12.783624800Z",
     "start_time": "2023-11-10T04:46:10.309174700Z"
    }
   },
   "id": "d07635807c86ec85"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|fraction|\n",
      "+--------+\n",
      "|    0.33|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "# solving in Spark SQL\n",
    "\n",
    "activity_df.createOrReplaceTempView('activity')\n",
    "\n",
    "spark.sql('''\n",
    "with tbl as (\n",
    "    select \n",
    "        *,\n",
    "        lead(event_date) over (partition by player_id order by event_date) as next_date,\n",
    "        row_number() over (partition by player_id order by event_date) as rn\n",
    "    from activity\n",
    ")\n",
    "select \n",
    "    round(\n",
    "    sum(case when datediff(next_date,event_date)=1 then 1 else 0 end)/count(*)\n",
    "    ,2) as fraction \n",
    "from tbl\n",
    "where rn=1;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:46:13.502862300Z",
     "start_time": "2023-11-10T04:46:12.312281500Z"
    }
   },
   "id": "ecf4fb5def9847b0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:46:14.337037700Z",
     "start_time": "2023-11-10T04:46:13.502862300Z"
    }
   },
   "id": "b884183042c60c90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
