{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1148. Article Views I](https://leetcode.com/problems/article-views-i/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c11e42ce944e8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Views\n",
    "<pre>\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| article_id    | int     |\n",
    "| author_id     | int     |\n",
    "| viewer_id     | int     |\n",
    "| view_date     | date    |\n",
    "+---------------+---------+\n",
    "</pre>\n",
    "There is no primary key (column with unique values) for this table, the table may have duplicate rows.\n",
    "Each row of this table indicates that some viewer viewed an article (written by some author) on some date. \n",
    "Note that equal author_id and viewer_id indicate the same person.\n",
    " \n",
    "\n",
    "Write a solution to find all the authors that viewed at least one of their own articles.\n",
    "\n",
    "Return the result table sorted by id in ascending order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Views table:\n",
    "<pre>\n",
    "+------------+-----------+-----------+------------+\n",
    "| article_id | author_id | viewer_id | view_date  |\n",
    "+------------+-----------+-----------+------------+\n",
    "| 1          | 3         | 5         | 2019-08-01 |\n",
    "| 1          | 3         | 6         | 2019-08-02 |\n",
    "| 2          | 7         | 7         | 2019-08-01 |\n",
    "| 2          | 7         | 6         | 2019-08-02 |\n",
    "| 4          | 7         | 1         | 2019-07-22 |\n",
    "| 3          | 4         | 4         | 2019-07-21 |\n",
    "| 3          | 4         | 4         | 2019-07-21 |\n",
    "+------------+-----------+-----------+------------+</pre>\n",
    "Output: \n",
    "<pre>\n",
    "+------+\n",
    "| id   |\n",
    "+------+\n",
    "| 4    |\n",
    "| 7    |\n",
    "+------+</pre>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a340e7790492a05"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 3, 5, '2019-08-01'], [1, 3, 6, '2019-08-02'], [2, 7, 7, '2019-08-01'], [2, 7, 6, '2019-08-02'], [4, 7, 1, '2019-07-22'], [3, 4, 4, '2019-07-21'], [3, 4, 4, '2019-07-21']]\n",
    "views = pd.DataFrame(data, columns=['article_id', 'author_id', 'viewer_id', 'view_date']).astype({'article_id':'Int64', 'author_id':'Int64', 'viewer_id':'Int64', 'view_date':'datetime64[ns]'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:25.258626600Z",
     "start_time": "2023-11-05T16:41:24.669600300Z"
    }
   },
   "id": "7ae06ec7a30f432f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 10:41:27 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 10:41:27 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 10:41:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# To pyspark schema\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "views_df = spark.createDataFrame(views)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:36.979139600Z",
     "start_time": "2023-11-05T16:41:25.268471900Z"
    }
   },
   "id": "14a2d9616b23d1fc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- article_id: long (nullable = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- viewer_id: long (nullable = true)\n",
      " |-- view_date: timestamp (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "views_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:37.028600400Z",
     "start_time": "2023-11-05T16:41:36.986526900Z"
    }
   },
   "id": "6d484e205f8b18df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---------+-------------------+\n",
      "|article_id|author_id|viewer_id|view_date          |\n",
      "+----------+---------+---------+-------------------+\n",
      "|1         |3        |5        |2019-08-01 00:00:00|\n",
      "|1         |3        |6        |2019-08-02 00:00:00|\n",
      "|2         |7        |7        |2019-08-01 00:00:00|\n",
      "|2         |7        |6        |2019-08-02 00:00:00|\n",
      "|4         |7        |1        |2019-07-22 00:00:00|\n",
      "|3         |4        |4        |2019-07-21 00:00:00|\n",
      "|3         |4        |4        |2019-07-21 00:00:00|\n",
      "+----------+---------+---------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "views_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:41.357155700Z",
     "start_time": "2023-11-05T16:41:37.035118400Z"
    }
   },
   "id": "ae647be0b9177562"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  4|\n",
      "|  7|\n",
      "+---+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# In spark Dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "views_df\\\n",
    "    .filter(F.col('author_id')==F.col('viewer_id'))\\\n",
    "    .select(F.col('author_id').alias('id'))\\\n",
    "    .distinct()\\\n",
    "    .orderBy('id')\\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:43.496550400Z",
     "start_time": "2023-11-05T16:41:41.345713700Z"
    }
   },
   "id": "55e5640ffe64dbb6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  4|\n",
      "|  7|\n",
      "+---+\n"
     ]
    }
   ],
   "source": [
    "#In spark SQL\n",
    "views_df.createOrReplaceTempView('views')\n",
    "\n",
    "spark.sql('''\n",
    "select distinct author_id as id\n",
    "from views\n",
    "where author_id=viewer_id\n",
    "order by id;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:44.504908400Z",
     "start_time": "2023-11-05T16:41:43.479881500Z"
    }
   },
   "id": "aa5e6325b40ca733"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:45.473631300Z",
     "start_time": "2023-11-05T16:41:44.478920600Z"
    }
   },
   "id": "4dad55b0fe283b5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:41:45.520502800Z",
     "start_time": "2023-11-05T16:41:45.473085600Z"
    }
   },
   "id": "8e6c943eb2db662a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
