{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1141. User Activity for the Past 30 Days I](https://leetcode.com/problems/user-activity-for-the-past-30-days-i/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "115377a829768015"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Activity\n",
    "\n",
    "<pre>+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| user_id       | int     |\n",
    "| session_id    | int     |\n",
    "| activity_date | date    |\n",
    "| activity_type | enum    |\n",
    "+---------------+---------+</pre>\n",
    "This table may have duplicate rows.\n",
    "The activity_type column is an ENUM (category) of type ('open_session', 'end_session', 'scroll_down', 'send_message').\n",
    "The table shows the user activities for a social media website. \n",
    "Note that each session belongs to exactly one user.\n",
    " \n",
    "\n",
    "Write a solution to find the daily active user count for a period of 30 days ending 2019-07-27 inclusively. A user was active on someday if they made at least one activity on that day.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "<pre>+---------+------------+---------------+---------------+\n",
    "| user_id | session_id | activity_date | activity_type |\n",
    "+---------+------------+---------------+---------------+\n",
    "| 1       | 1          | 2019-07-20    | open_session  |\n",
    "| 1       | 1          | 2019-07-20    | scroll_down   |\n",
    "| 1       | 1          | 2019-07-20    | end_session   |\n",
    "| 2       | 4          | 2019-07-20    | open_session  |\n",
    "| 2       | 4          | 2019-07-21    | send_message  |\n",
    "| 2       | 4          | 2019-07-21    | end_session   |\n",
    "| 3       | 2          | 2019-07-21    | open_session  |\n",
    "| 3       | 2          | 2019-07-21    | send_message  |\n",
    "| 3       | 2          | 2019-07-21    | end_session   |\n",
    "| 4       | 3          | 2019-06-25    | open_session  |\n",
    "| 4       | 3          | 2019-06-25    | end_session   |\n",
    "+---------+------------+---------------+---------------+</pre>\n",
    "Output: \n",
    "<pre>+------------+--------------+ \n",
    "| day        | active_users |\n",
    "+------------+--------------+ \n",
    "| 2019-07-20 | 2            |\n",
    "| 2019-07-21 | 2            |\n",
    "+------------+--------------+</pre>\n",
    "Explanation: Note that we do not care about days with zero active users."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a57120498dd7af"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#pandas schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 1, '2019-07-20', 'open_session'], [1, 1, '2019-07-20', 'scroll_down'], [1, 1, '2019-07-20', 'end_session'],\n",
    "        [2, 4, '2019-07-20', 'open_session'], [2, 4, '2019-07-21', 'send_message'], [2, 4, '2019-07-21', 'end_session'],\n",
    "        [3, 2, '2019-07-21', 'open_session'], [3, 2, '2019-07-21', 'send_message'], [3, 2, '2019-07-21', 'end_session'],\n",
    "        [4, 3, '2019-06-25', 'open_session'], [4, 3, '2019-06-25', 'end_session']]\n",
    "activity = pd.DataFrame(data, columns=['user_id', 'session_id', 'activity_date', 'activity_type']).astype(\n",
    "    {'user_id': 'Int64', 'session_id': 'Int64', 'activity_date': 'datetime64[ns]', 'activity_type': 'object'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T03:21:13.828047100Z",
     "start_time": "2023-11-11T03:21:13.315361800Z"
    }
   },
   "id": "9f9fd3c94e8a106d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/10 06:25:41 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/10 06:25:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/10 06:25:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------------+-------------+\n",
      "|user_id|session_id|      activity_date|activity_type|\n",
      "+-------+----------+-------------------+-------------+\n",
      "|      1|         1|2019-07-20 00:00:00| open_session|\n",
      "|      1|         1|2019-07-20 00:00:00|  scroll_down|\n",
      "|      1|         1|2019-07-20 00:00:00|  end_session|\n",
      "|      2|         4|2019-07-20 00:00:00| open_session|\n",
      "|      2|         4|2019-07-21 00:00:00| send_message|\n",
      "|      2|         4|2019-07-21 00:00:00|  end_session|\n",
      "|      3|         2|2019-07-21 00:00:00| open_session|\n",
      "|      3|         2|2019-07-21 00:00:00| send_message|\n",
      "|      3|         2|2019-07-21 00:00:00|  end_session|\n",
      "|      4|         3|2019-06-25 00:00:00| open_session|\n",
      "|      4|         3|2019-06-25 00:00:00|  end_session|\n",
      "+-------+----------+-------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "#converting to spark dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "activity_df = spark.createDataFrame(activity)\n",
    "activity_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T03:21:26.297995700Z",
     "start_time": "2023-11-11T03:21:13.835034800Z"
    }
   },
   "id": "5adcd9312f993c00"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|      activity_date|active_users|\n",
      "+-------------------+------------+\n",
      "|2019-07-21 00:00:00|           2|\n",
      "|2019-07-20 00:00:00|           2|\n",
      "+-------------------+------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# solving in spark dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "activity_df.filter(\n",
    "    (F.col('activity_date') <= '2019-07-27')\n",
    "    &\n",
    "    (F.col('activity_date') >= F.date_sub(F.lit('2019-07-27'), 29))) \\\n",
    "    .groupBy('activity_date').agg(F.count_distinct('user_id').alias('active_users')) \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T03:21:28.408742500Z",
     "start_time": "2023-11-11T03:21:26.291871600Z"
    }
   },
   "id": "54ff61882826af31"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|                day|active_users|\n",
      "+-------------------+------------+\n",
      "|2019-07-21 00:00:00|           2|\n",
      "|2019-07-20 00:00:00|           2|\n",
      "+-------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# solving in spark SQL\n",
    "\n",
    "activity_df.createOrReplaceTempView('activity')\n",
    "\n",
    "spark.sql('''\n",
    "select activity_date as day, count(distinct user_id) as active_users\n",
    "from activity\n",
    "-- for mysql:  where activity_date<='2019-07-27' and activity_date>=date_sub('2019-07-27', interval 29 day)\n",
    "where activity_date<='2019-07-27' and activity_date>=date_sub('2019-07-27',  29)\n",
    "group by activity_date;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T03:21:29.443548400Z",
     "start_time": "2023-11-11T03:21:28.383713Z"
    }
   },
   "id": "e92002d397a8aaf4"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-11T03:21:30.349088900Z",
     "start_time": "2023-11-11T03:21:29.432150300Z"
    }
   },
   "id": "4b71904c53501aaf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
