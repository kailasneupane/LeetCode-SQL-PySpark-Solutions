{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1661. Average Time of Process per Machine](https://leetcode.com/problems/average-time-of-process-per-machine/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9b27449f01e68fe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Activity\n",
    "\n",
    "<pre>+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| machine_id     | int     |\n",
    "| process_id     | int     |\n",
    "| activity_type  | enum    |\n",
    "| timestamp      | float   |\n",
    "+----------------+---------+</pre>\n",
    "The table shows the user activities for a factory website.\n",
    "(machine_id, process_id, activity_type) is the primary key (combination of columns with unique values) of this table.\n",
    "machine_id is the ID of a machine.\n",
    "process_id is the ID of a process running on the machine with ID machine_id.\n",
    "activity_type is an ENUM (category) of type ('start', 'end').\n",
    "timestamp is a float representing the current time in seconds.\n",
    "'start' means the machine starts the process at the given timestamp and 'end' means the machine ends the process at the given timestamp.\n",
    "The 'start' timestamp will always be before the 'end' timestamp for every (machine_id, process_id) pair.\n",
    " \n",
    "\n",
    "There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
    "\n",
    "The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
    "\n",
    "The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activity table:\n",
    "<pre>+------------+------------+---------------+-----------+\n",
    "| machine_id | process_id | activity_type | timestamp |\n",
    "+------------+------------+---------------+-----------+\n",
    "| 0          | 0          | start         | 0.712     |\n",
    "| 0          | 0          | end           | 1.520     |\n",
    "| 0          | 1          | start         | 3.140     |\n",
    "| 0          | 1          | end           | 4.120     |\n",
    "| 1          | 0          | start         | 0.550     |\n",
    "| 1          | 0          | end           | 1.550     |\n",
    "| 1          | 1          | start         | 0.430     |\n",
    "| 1          | 1          | end           | 1.420     |\n",
    "| 2          | 0          | start         | 4.100     |\n",
    "| 2          | 0          | end           | 4.512     |\n",
    "| 2          | 1          | start         | 2.500     |\n",
    "| 2          | 1          | end           | 5.000     |\n",
    "+------------+------------+---------------+-----------+</pre>\n",
    "Output: \n",
    "<pre>+------------+-----------------+\n",
    "| machine_id | processing_time |\n",
    "+------------+-----------------+\n",
    "| 0          | 0.894           |\n",
    "| 1          | 0.995           |\n",
    "| 2          | 1.456           |\n",
    "+------------+-----------------+</pre>\n",
    "Explanation: \n",
    "There are 3 machines running 2 processes each.\n",
    "Machine 0's average time is ((1.520 - 0.712) + (4.120 - 3.140)) / 2 = 0.894\n",
    "Machine 1's average time is ((1.550 - 0.550) + (1.420 - 0.430)) / 2 = 0.995\n",
    "Machine 2's average time is ((4.512 - 4.100) + (5.000 - 2.500)) / 2 = 1.456"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8561645285a3c14c"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas Schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[0, 0, 'start', 0.712], [0, 0, 'end', 1.52], [0, 1, 'start', 3.14], [0, 1, 'end', 4.12], [1, 0, 'start', 0.55],\n",
    "        [1, 0, 'end', 1.55], [1, 1, 'start', 0.43], [1, 1, 'end', 1.42], [2, 0, 'start', 4.1], [2, 0, 'end', 4.512],\n",
    "        [2, 1, 'start', 2.5], [2, 1, 'end', 5]]\n",
    "activity = pd.DataFrame(data, columns=['machine_id', 'process_id', 'activity_type', 'timestamp']).astype(\n",
    "    {'machine_id': 'Int64', 'process_id': 'Int64', 'activity_type': 'object', 'timestamp': 'Float64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:59:27.284183600Z",
     "start_time": "2023-11-05T18:59:26.575083800Z"
    }
   },
   "id": "fd4fbdd5f2526a3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:05:00 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:05:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:05:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------+---------+\n",
      "|machine_id|process_id|activity_type|timestamp|\n",
      "+----------+----------+-------------+---------+\n",
      "|         0|         0|        start|    0.712|\n",
      "|         0|         0|          end|     1.52|\n",
      "|         0|         1|        start|     3.14|\n",
      "|         0|         1|          end|     4.12|\n",
      "|         1|         0|        start|     0.55|\n",
      "|         1|         0|          end|     1.55|\n",
      "|         1|         1|        start|     0.43|\n",
      "|         1|         1|          end|     1.42|\n",
      "|         2|         0|        start|      4.1|\n",
      "|         2|         0|          end|    4.512|\n",
      "|         2|         1|        start|      2.5|\n",
      "|         2|         1|          end|      5.0|\n",
      "+----------+----------+-------------+---------+\n"
     ]
    }
   ],
   "source": [
    "#to pyspark schema\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "activity_df = spark.createDataFrame(activity)\n",
    "activity_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:59:44.647732200Z",
     "start_time": "2023-11-05T18:59:27.280583300Z"
    }
   },
   "id": "42ee998471990bcc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|machine_id|processing_time|\n",
      "+----------+---------------+\n",
      "|         0|          0.894|\n",
      "|         1|          0.995|\n",
      "|         2|          1.456|\n",
      "+----------+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# In spark Dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "activity_df \\\n",
    "    .groupBy('machine_id', 'process_id') \\\n",
    "    .agg(F.sum(\n",
    "    F.when(activity_df['activity_type'] == 'start', -1 * activity_df['timestamp']) \\\n",
    "        .otherwise(activity_df['timestamp'])).alias('intermediate_sum')) \\\n",
    "    .groupBy('machine_id') \\\n",
    "    .agg(F.round(F.avg('intermediate_sum'), 3).alias('processing_time')) \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:59:47.374654500Z",
     "start_time": "2023-11-05T18:59:44.645674300Z"
    }
   },
   "id": "4ed462a071ca3642"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|machine_id|processing_time|\n",
      "+----------+---------------+\n",
      "|         0|          0.894|\n",
      "|         1|          0.995|\n",
      "|         2|          1.456|\n",
      "+----------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# In spark SQL\n",
    "\n",
    "activity_df.createOrReplaceTempView('activity')\n",
    "\n",
    "spark.sql('''\n",
    "with tbl1 as (\n",
    "select machine_id, process_id, \n",
    "    sum(case when activity_type='start' then -1*timestamp else timestamp end) as intermediate_sum \n",
    "from activity\n",
    "group by machine_id, process_id\n",
    ")\n",
    "select machine_id, round(avg(intermediate_sum),3) as processing_time\n",
    "from tbl1\n",
    "group by machine_id;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:59:48.855668100Z",
     "start_time": "2023-11-05T18:59:47.367406300Z"
    }
   },
   "id": "80b9d8d83571439b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:59:49.748009700Z",
     "start_time": "2023-11-05T18:59:48.835499300Z"
    }
   },
   "id": "6c357f6a7ab3c2c9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
