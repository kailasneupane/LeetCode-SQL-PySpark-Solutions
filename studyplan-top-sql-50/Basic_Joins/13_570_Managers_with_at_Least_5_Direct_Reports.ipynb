{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [570. Managers with at Least 5 Direct Reports](https://leetcode.com/problems/managers-with-at-least-5-direct-reports/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b89f5d7b832c834"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Employee\n",
    "\n",
    "<pre>+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| id          | int     |\n",
    "| name        | varchar |\n",
    "| department  | varchar |\n",
    "| managerId   | int     |\n",
    "+-------------+---------+</pre>\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table indicates the name of an employee, their department, and the id of their manager.\n",
    "If managerId is null, then the employee does not have a manager.\n",
    "No employee will be the manager of themself.\n",
    " \n",
    "\n",
    "Write a solution to find managers with at least five direct reports.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "<pre>+-----+-------+------------+-----------+\n",
    "| id  | name  | department | managerId |\n",
    "+-----+-------+------------+-----------+\n",
    "| 101 | John  | A          | None      |\n",
    "| 102 | Dan   | A          | 101       |\n",
    "| 103 | James | A          | 101       |\n",
    "| 104 | Amy   | A          | 101       |\n",
    "| 105 | Anne  | A          | 101       |\n",
    "| 106 | Ron   | B          | 101       |\n",
    "+-----+-------+------------+-----------+</pre>\n",
    "Output: \n",
    "<pre>+------+\n",
    "| name |\n",
    "+------+\n",
    "| John |\n",
    "+------+</pre>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b6f0434a396216b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[101, 'John', 'A', None], [102, 'Dan', 'A', 101], [103, 'James', 'A', 101], [104, 'Amy', 'A', 101], [105, 'Anne', 'A', 101], [106, 'Ron', 'B', 101]]\n",
    "employee = pd.DataFrame(data, columns=['id', 'name', 'department', 'managerId']).astype({'id':'Int64', 'name':'object', 'department':'object', 'managerId':'Int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:00:55.617190700Z",
     "start_time": "2023-11-05T19:00:54.882279800Z"
    }
   },
   "id": "c7cd1ba66f6a6cdc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# to pyspark schema\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"managerId\", IntegerType(), True)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:00:55.751997100Z",
     "start_time": "2023-11-05T19:00:55.616132800Z"
    }
   },
   "id": "4e00eb4aa7c62213"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:06:36 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:06:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:06:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+---------+\n",
      "|id |name |department|managerId|\n",
      "+---+-----+----------+---------+\n",
      "|101|John |A         |null     |\n",
      "|102|Dan  |A         |101      |\n",
      "|103|James|A         |101      |\n",
      "|104|Amy  |A         |101      |\n",
      "|105|Anne |A         |101      |\n",
      "|106|Ron  |B         |101      |\n",
      "+---+-----+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employee_df = spark.createDataFrame(data,schema=schema)\n",
    "employee_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:01:12.008869400Z",
     "start_time": "2023-11-05T19:00:55.732960Z"
    }
   },
   "id": "ca7cde997baaa96f"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|John|\n",
      "+----+\n"
     ]
    }
   ],
   "source": [
    "# in Spark Dataframe\n",
    "\n",
    "employee_df.select('name').filter(F.col('id').isin(\n",
    "        list(employee_df.select('managerId').groupBy('managerId').agg(F.count(F.col('managerId')).alias('count')).filter(\n",
    "        F.col('count') >= 5).select('managerId').rdd.map(lambda x:x[0]).collect())\n",
    ")).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:01:15.111346200Z",
     "start_time": "2023-11-05T19:01:12.006298600Z"
    }
   },
   "id": "9c647b45dc8ee9da"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|name|\n",
      "+----+\n",
      "|John|\n",
      "+----+\n"
     ]
    }
   ],
   "source": [
    "# in Spark SQL\n",
    "employee_df.createOrReplaceTempView('employee')\n",
    "spark.sql('''\n",
    "select name\n",
    "from employee\n",
    "where id in (select managerId from employee group by managerId having count(managerId)>=5)\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:01:16.885108100Z",
     "start_time": "2023-11-05T19:01:15.100758800Z"
    }
   },
   "id": "fbe69d8b8cc3845"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:01:17.652441100Z",
     "start_time": "2023-11-05T19:01:16.867080500Z"
    }
   },
   "id": "3b09d0d3e7837236"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:01:17.699399100Z",
     "start_time": "2023-11-05T19:01:17.645279500Z"
    }
   },
   "id": "ac1c60351e9251ce"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
