{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [577. Employee Bonus](https://leetcode.com/problems/employee-bonus/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91be3842eb69281c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Employee\n",
    "\n",
    "<pre>+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| empId       | int     |\n",
    "| name        | varchar |\n",
    "| supervisor  | int     |\n",
    "| salary      | int     |\n",
    "+-------------+---------+</pre>\n",
    "empId is the column with unique values for this table.\n",
    "Each row of this table indicates the name and the ID of an employee in addition to their salary and the id of their manager.\n",
    " \n",
    "\n",
    "Table: Bonus\n",
    "\n",
    "<pre>+-------------+------+\n",
    "| Column Name | Type |\n",
    "+-------------+------+\n",
    "| empId       | int  |\n",
    "| bonus       | int  |\n",
    "+-------------+------+</pre>\n",
    "empId is the column of unique values for this table.\n",
    "empId is a foreign key (reference column) to empId from the Employee table.\n",
    "Each row of this table contains the id of an employee and their respective bonus.\n",
    " \n",
    "\n",
    "Write a solution to report the name and bonus amount of each employee with a bonus less than 1000.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "<pre>+-------+--------+------------+--------+\n",
    "| empId | name   | supervisor | salary |\n",
    "+-------+--------+------------+--------+\n",
    "| 3     | Brad   | null       | 4000   |\n",
    "| 1     | John   | 3          | 1000   |\n",
    "| 2     | Dan    | 3          | 2000   |\n",
    "| 4     | Thomas | 3          | 4000   |\n",
    "+-------+--------+------------+--------+</pre>\n",
    "Bonus table:\n",
    "<pre>+-------+-------+\n",
    "| empId | bonus |\n",
    "+-------+-------+\n",
    "| 2     | 500   |\n",
    "| 4     | 2000  |\n",
    "+-------+-------+</pre>\n",
    "Output: \n",
    "<pre>+------+-------+\n",
    "| name | bonus |\n",
    "+------+-------+\n",
    "| Brad | null  |\n",
    "| John | null  |\n",
    "| Dan  | 500   |\n",
    "+------+-------+</pre>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9537d57ae5593ff"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas Schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[3, 'Brad', None, 4000], [1, 'John', 3, 1000], [2, 'Dan', 3, 2000], [4, 'Thomas', 3, 4000]]\n",
    "employee = pd.DataFrame(data, columns=['empId', 'name', 'supervisor', 'salary']).astype(\n",
    "    {'empId': 'Int64', 'name': 'object', 'supervisor': 'Int64', 'salary': 'Int64'})\n",
    "data2 = [[2, 500], [4, 2000]]\n",
    "bonus = pd.DataFrame(data2, columns=['empId', 'bonus']).astype({'empId': 'Int64', 'bonus': 'Int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:34.093581300Z",
     "start_time": "2023-11-05T18:58:33.461448Z"
    }
   },
   "id": "45168f69e1098831"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:04:02 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:04:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:04:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# to pyspark schema\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "schema_employee = StructType([\n",
    "    StructField(\"empId\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"supervisor\", IntegerType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "employee_df = spark.createDataFrame(data, schema_employee)\n",
    "bonus_df = spark.createDataFrame(bonus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:46.391828300Z",
     "start_time": "2023-11-05T18:58:34.092568300Z"
    }
   },
   "id": "8450a51715fbbea5"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+------+\n",
      "|empId|name  |supervisor|salary|\n",
      "+-----+------+----------+------+\n",
      "|3    |Brad  |null      |4000  |\n",
      "|1    |John  |3         |1000  |\n",
      "|2    |Dan   |3         |2000  |\n",
      "|4    |Thomas|3         |4000  |\n",
      "+-----+------+----------+------+\n"
     ]
    }
   ],
   "source": [
    "employee_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:50.832369500Z",
     "start_time": "2023-11-05T18:58:46.400611500Z"
    }
   },
   "id": "33456f1da390778c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- empId: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- supervisor: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "employee_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:50.903166800Z",
     "start_time": "2023-11-05T18:58:50.825886600Z"
    }
   },
   "id": "305031adb98a763"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|empId|bonus|\n",
      "+-----+-----+\n",
      "|2    |500  |\n",
      "|4    |2000 |\n",
      "+-----+-----+\n"
     ]
    }
   ],
   "source": [
    "bonus_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:51.880858700Z",
     "start_time": "2023-11-05T18:58:50.842652900Z"
    }
   },
   "id": "573427d8260dee6f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|bonus|\n",
      "+----+-----+\n",
      "|Brad| null|\n",
      "|John| null|\n",
      "| Dan|  500|\n",
      "+----+-----+\n"
     ]
    }
   ],
   "source": [
    "# In spark Dataframe\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "employee_df.join(bonus_df, on=['empId'], how='left') \\\n",
    "    .filter((F.col('bonus') < 1000) | (F.col('bonus').isNull())) \\\n",
    "    .select('name', 'bonus').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:54.629645300Z",
     "start_time": "2023-11-05T18:58:51.868966700Z"
    }
   },
   "id": "5edf387ade8d5e05"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 13:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|name|bonus|\n",
      "+----+-----+\n",
      "|Brad| null|\n",
      "|John| null|\n",
      "| Dan|  500|\n",
      "+----+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# In spark SQL\n",
    "\n",
    "employee_df.createOrReplaceTempView('employee')\n",
    "bonus_df.createOrReplaceTempView('bonus')\n",
    "\n",
    "spark.sql('''\n",
    "select name,bonus from employee\n",
    "left join bonus\n",
    "on employee.empId=bonus.empId\n",
    "where bonus is null or bonus<1000;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:56.322360900Z",
     "start_time": "2023-11-05T18:58:54.632849300Z"
    }
   },
   "id": "4b6e94de4e086281"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:57.132732500Z",
     "start_time": "2023-11-05T18:58:56.363746Z"
    }
   },
   "id": "d98609f182eaeb12"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T18:58:57.158393900Z",
     "start_time": "2023-11-05T18:58:57.061436300Z"
    }
   },
   "id": "bf84b27c74b8cb68"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
