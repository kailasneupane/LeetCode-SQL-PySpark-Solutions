{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1378. Replace employee id with the unique identifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f2ef0c272e6c920"
  },
  {
   "cell_type": "raw",
   "source": [
    "Table: Employees\n",
    "\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| name          | varchar |\n",
    "+---------------+---------+\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table contains the id and the name of an employee in a company.\n",
    " \n",
    "\n",
    "Table: EmployeeUNI\n",
    "\n",
    "+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| id            | int     |\n",
    "| unique_id     | int     |\n",
    "+---------------+---------+\n",
    "(id, unique_id) is the primary key (combination of columns with unique values) for this table.\n",
    "Each row of this table contains the id and the corresponding unique id of an employee in the company.\n",
    " \n",
    "\n",
    "Write a solution to show the unique ID of each user, If a user does not have a unique ID replace just show null.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employees table:\n",
    "+----+----------+\n",
    "| id | name     |\n",
    "+----+----------+\n",
    "| 1  | Alice    |\n",
    "| 7  | Bob      |\n",
    "| 11 | Meir     |\n",
    "| 90 | Winston  |\n",
    "| 3  | Jonathan |\n",
    "+----+----------+\n",
    "EmployeeUNI table:\n",
    "+----+-----------+\n",
    "| id | unique_id |\n",
    "+----+-----------+\n",
    "| 3  | 1         |\n",
    "| 11 | 2         |\n",
    "| 90 | 3         |\n",
    "+----+-----------+\n",
    "Output: \n",
    "+-----------+----------+\n",
    "| unique_id | name     |\n",
    "+-----------+----------+\n",
    "| null      | Alice    |\n",
    "| null      | Bob      |\n",
    "| 2         | Meir     |\n",
    "| 3         | Winston  |\n",
    "| 1         | Jonathan |\n",
    "+-----------+----------+\n",
    "Explanation: \n",
    "Alice and Bob do not have a unique ID, We will show null instead.\n",
    "The unique ID of Meir is 2.\n",
    "The unique ID of Winston is 3.\n",
    "The unique ID of Jonathan is 1."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3d50c6fc977ee5f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [[1, 'Alice'], [7, 'Bob'], [11, 'Meir'], [90, 'Winston'], [3, 'Jonathan']]\n",
    "employees = pd.DataFrame(data, columns=['id', 'name']).astype({'id':'int64', 'name':'object'})\n",
    "data = [[3, 1], [11, 2], [90, 3]]\n",
    "employee_uni = pd.DataFrame(data, columns=['id', 'unique_id']).astype({'id':'int64', 'unique_id':'int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:17:05.344169100Z",
     "start_time": "2023-11-01T03:17:04.036165Z"
    }
   },
   "id": "9858a8e925b70a5a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:17:05.345324200Z",
     "start_time": "2023-11-01T03:17:04.719232Z"
    }
   },
   "id": "c530fc3d2af12256"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/10/31 19:40:14 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/10/31 19:40:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/31 19:40:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/10/31 19:40:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/10/31 19:40:18 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|id |name    |\n",
      "+---+--------+\n",
      "|1  |Alice   |\n",
      "|7  |Bob     |\n",
      "|11 |Meir    |\n",
      "|90 |Winston |\n",
      "|3  |Jonathan|\n",
      "+---+--------+\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employees_df = spark.createDataFrame(employees)\n",
    "employees_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:17:21.979930100Z",
     "start_time": "2023-11-01T03:17:04.796291500Z"
    }
   },
   "id": "54538ea9e380a87e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|id |unique_id|\n",
      "+---+---------+\n",
      "|3  |1        |\n",
      "|11 |2        |\n",
      "|90 |3        |\n",
      "+---+---------+\n"
     ]
    }
   ],
   "source": [
    "employee_uni_df = spark.createDataFrame(employee_uni)\n",
    "employee_uni_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:17:22.263591Z",
     "start_time": "2023-11-01T03:17:21.402839900Z"
    }
   },
   "id": "176a4a8e320f176e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     null|   Alice|\n",
      "|     null|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "# in spark Dafaframe\n",
    "\n",
    "employees_df.join(employee_uni_df,on=['id'],how='left').select('unique_id','name').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:27:17.462541300Z",
     "start_time": "2023-11-01T03:27:16.055587900Z"
    }
   },
   "id": "7c265c30edfbf76a"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|unique_id|    name|\n",
      "+---------+--------+\n",
      "|     null|   Alice|\n",
      "|     null|     Bob|\n",
      "|        2|    Meir|\n",
      "|        3| Winston|\n",
      "|        1|Jonathan|\n",
      "+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "# in spark SQL\n",
    "\n",
    "employees_df.createOrReplaceTempView('employees')\n",
    "employee_uni_df.createOrReplaceTempView('employee_uni')\n",
    "\n",
    "spark.sql('''\n",
    "select unique_id, name from employees left join employee_uni on employees.id = employee_uni.id;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:29:37.092104400Z",
     "start_time": "2023-11-01T03:29:35.251543400Z"
    }
   },
   "id": "89f827a905c69a79"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T03:29:53.375165300Z",
     "start_time": "2023-11-01T03:29:52.450877200Z"
    }
   },
   "id": "6f51ccc802d24c64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "405f83bfcf69bb8e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
