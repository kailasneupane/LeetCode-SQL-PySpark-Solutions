{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [185. Department Top Three Salaries](https://leetcode.com/problems/department-top-three-salaries/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aaad642b5f03c889"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Employee\n",
    "\n",
    "<pre>+--------------+---------+\n",
    "| Column Name  | Type    |\n",
    "+--------------+---------+\n",
    "| id           | int     |\n",
    "| name         | varchar |\n",
    "| salary       | int     |\n",
    "| departmentId | int     |\n",
    "+--------------+---------+</pre>\n",
    "id is the primary key (column with unique values) for this table.\n",
    "departmentId is a foreign key (reference column) of the ID from the Department table.\n",
    "Each row of this table indicates the ID, name, and salary of an employee. It also contains the ID of their department.\n",
    " \n",
    "\n",
    "Table: Department\n",
    "\n",
    "<pre>+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| id          | int     |\n",
    "| name        | varchar |\n",
    "+-------------+---------+</pre>\n",
    "id is the primary key (column with unique values) for this table.\n",
    "Each row of this table indicates the ID of a department and its name.\n",
    " \n",
    "\n",
    "A company's executives are interested in seeing who earns the most money in each of the company's departments. A high earner in a department is an employee who has a salary in the top three unique salaries for that department.\n",
    "\n",
    "Write a solution to find the employees who are high earners in each of the departments.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Employee table:\n",
    "<pre>+----+-------+--------+--------------+\n",
    "| id | name  | salary | departmentId |\n",
    "+----+-------+--------+--------------+\n",
    "| 1  | Joe   | 85000  | 1            |\n",
    "| 2  | Henry | 80000  | 2            |\n",
    "| 3  | Sam   | 60000  | 2            |\n",
    "| 4  | Max   | 90000  | 1            |\n",
    "| 5  | Janet | 69000  | 1            |\n",
    "| 6  | Randy | 85000  | 1            |\n",
    "| 7  | Will  | 70000  | 1            |\n",
    "+----+-------+--------+--------------+</pre>\n",
    "Department table:\n",
    "<pre>+----+-------+\n",
    "| id | name  |\n",
    "+----+-------+\n",
    "| 1  | IT    |\n",
    "| 2  | Sales |\n",
    "+----+-------+</pre>\n",
    "Output: \n",
    "<pre>+------------+----------+--------+\n",
    "| Department | Employee | Salary |\n",
    "+------------+----------+--------+\n",
    "| IT         | Max      | 90000  |\n",
    "| IT         | Joe      | 85000  |\n",
    "| IT         | Randy    | 85000  |\n",
    "| IT         | Will     | 70000  |\n",
    "| Sales      | Henry    | 80000  |\n",
    "| Sales      | Sam      | 60000  |\n",
    "+------------+----------+--------+</pre>\n",
    "Explanation: \n",
    "In the IT department:\n",
    "- Max earns the highest unique salary\n",
    "- Both Randy and Joe earn the second-highest unique salary\n",
    "- Will earns the third-highest unique salary\n",
    "\n",
    "In the Sales department:\n",
    "- Henry earns the highest salary\n",
    "- Sam earns the second-highest salary\n",
    "- There is no third-highest salary as there are only two employees"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c266e9d5c8610c85"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 'Joe', 85000, 1], [2, 'Henry', 80000, 2], [3, 'Sam', 60000, 2], [4, 'Max', 90000, 1],\n",
    "        [5, 'Janet', 69000, 1], [6, 'Randy', 85000, 1], [7, 'Will', 70000, 1]]\n",
    "employee = pd.DataFrame(data, columns=['id', 'name', 'salary', 'departmentId']).astype(\n",
    "    {'id': 'Int64', 'name': 'object', 'salary': 'Int64', 'departmentId': 'Int64'})\n",
    "data = [[1, 'IT'], [2, 'Sales']]\n",
    "department = pd.DataFrame(data, columns=['id', 'name']).astype({'id': 'Int64', 'name': 'object'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:13.586173Z",
     "start_time": "2023-11-07T04:14:12.694099600Z"
    }
   },
   "id": "142dffd62440c5c7"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/06 16:14:37 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/06 16:14:37 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/06 16:14:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------------+\n",
      "|id |name |salary|departmentId|\n",
      "+---+-----+------+------------+\n",
      "|1  |Joe  |85000 |1           |\n",
      "|2  |Henry|80000 |2           |\n",
      "|3  |Sam  |60000 |2           |\n",
      "|4  |Max  |90000 |1           |\n",
      "|5  |Janet|69000 |1           |\n",
      "|6  |Randy|85000 |1           |\n",
      "|7  |Will |70000 |1           |\n",
      "+---+-----+------+------------+\n"
     ]
    }
   ],
   "source": [
    "# pandas df to spark df\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employee_df = spark.createDataFrame(employee)\n",
    "employee_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:30.672687600Z",
     "start_time": "2023-11-07T04:14:13.580606500Z"
    }
   },
   "id": "4e00eb4aa7c62213"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|id |name |\n",
      "+---+-----+\n",
      "|1  |IT   |\n",
      "|2  |Sales|\n",
      "+---+-----+\n"
     ]
    }
   ],
   "source": [
    "department_df = spark.createDataFrame(department)\n",
    "department_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:31.741344400Z",
     "start_time": "2023-11-07T04:14:30.670672200Z"
    }
   },
   "id": "2f7cc761eb54df29"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:=================================================>       (14 + 2) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|department|employee|salary|\n",
      "+----------+--------+------+\n",
      "|        IT|     Max| 90000|\n",
      "|        IT|     Joe| 85000|\n",
      "|        IT|   Randy| 85000|\n",
      "|        IT|    Will| 70000|\n",
      "|     Sales|   Henry| 80000|\n",
      "|     Sales|     Sam| 60000|\n",
      "+----------+--------+------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import window\n",
    "#  solving in Spark Dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "employee_df.join(department_df.withColumnRenamed('name', 'department'),\n",
    "                 on=employee_df['departmentId'] == department_df['id'], how='left'). \\\n",
    "    select('department', F.col('name').alias('employee'), 'salary'). \\\n",
    "    withColumn('dr', F.dense_rank().over(window.Window.partitionBy('department').orderBy(F.col('salary').desc()))). \\\n",
    "    filter(F.col('dr') <= 3). \\\n",
    "    drop('dr'). \\\n",
    "    orderBy('department', F.col('salary').desc()).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:35.787892Z",
     "start_time": "2023-11-07T04:14:31.732847300Z"
    }
   },
   "id": "9c647b45dc8ee9da"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+------+\n",
      "|Department|Employee|Salary|\n",
      "+----------+--------+------+\n",
      "|        IT|     Max| 90000|\n",
      "|        IT|     Joe| 85000|\n",
      "|        IT|   Randy| 85000|\n",
      "|        IT|    Will| 70000|\n",
      "|     Sales|   Henry| 80000|\n",
      "|     Sales|     Sam| 60000|\n",
      "+----------+--------+------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# in Spark SQL\n",
    "employee_df.createOrReplaceTempView('employee')\n",
    "department_df.createOrReplaceTempView('department')\n",
    "\n",
    "spark.sql('''\n",
    "select department.name as Department, tbl.name as Employee, Salary\n",
    "from (\n",
    "select departmentid, name, salary,\n",
    "dense_rank() over (partition by departmentid order by salary desc) as dr\n",
    "from employee\n",
    ") tbl\n",
    "left join department on\n",
    "department.id = tbl.departmentid\n",
    "where dr<=3\n",
    "order by department, salary desc; \n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:37.549882500Z",
     "start_time": "2023-11-07T04:14:35.779882Z"
    }
   },
   "id": "fbe69d8b8cc3845"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T04:14:38.451146600Z",
     "start_time": "2023-11-07T04:14:37.535812200Z"
    }
   },
   "id": "3b09d0d3e7837236"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
