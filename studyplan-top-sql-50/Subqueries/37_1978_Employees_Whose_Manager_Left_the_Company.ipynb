{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1978. Employees Whose Manager Left the Company](https://leetcode.com/problems/employees-whose-manager-left-the-company/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "647f189b42580e16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Employees\n",
    "\n",
    "<pre>+-------------+----------+\n",
    "| Column Name | Type     |\n",
    "+-------------+----------+\n",
    "| employee_id | int      |\n",
    "| name        | varchar  |\n",
    "| manager_id  | int      |\n",
    "| salary      | int      |\n",
    "+-------------+----------+</pre>\n",
    "In SQL, employee_id is the primary key for this table.\n",
    "This table contains information about the employees, their salary, and the ID of their manager. Some employees do not have a manager (manager_id is null). \n",
    " \n",
    "\n",
    "Find the IDs of the employees whose salary is strictly less than dollar 30000 and whose manager left the company. When a manager leaves the company, their information is deleted from the Employees table, but the reports still have their manager_id set to the manager that left.\n",
    "\n",
    "Return the result table ordered by employee_id.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input:  \n",
    "Employees table:\n",
    "<pre>+-------------+-----------+------------+--------+\n",
    "| employee_id | name      | manager_id | salary |\n",
    "+-------------+-----------+------------+--------+\n",
    "| 3           | Mila      | 9          | 60301  |\n",
    "| 12          | Antonella | null       | 31000  |\n",
    "| 13          | Emery     | null       | 67084  |\n",
    "| 1           | Kalel     | 11         | 21241  |\n",
    "| 9           | Mikaela   | null       | 50937  |\n",
    "| 11          | Joziah    | 6          | 28485  |\n",
    "+-------------+-----------+------------+--------+</pre>\n",
    "Output: \n",
    "<pre>+-------------+\n",
    "| employee_id |\n",
    "+-------------+\n",
    "| 11          |\n",
    "+-------------+</pre>\n",
    "\n",
    "Explanation: \n",
    "The employees with a salary less than $30000 are 1 (Kalel) and 11 (Joziah).\n",
    "Kalel's manager is employee 11, who is still in the company (Joziah).\n",
    "Joziah's manager is employee 6, who left the company because there is no row for employee 6 as it was deleted."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ce72c457306fb23"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#pandas schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[3, 'Mila', 9, 60301], [12, 'Antonella', None, 31000], [13, 'Emery', None, 67084], [1, 'Kalel', 11, 21241],\n",
    "        [9, 'Mikaela', None, 50937], [11, 'Joziah', 6, 28485]]\n",
    "employees = pd.DataFrame(data, columns=['employee_id', 'name', 'manager_id', 'salary']).astype(\n",
    "    {'employee_id': 'Int64', 'name': 'object', 'manager_id': 'Int64', 'salary': 'Int64'})\n",
    "\n",
    "# spark has issues with null in Int64 of pandas, hence converting to str for now. Will convert to int after loading in spark.\n",
    "employees['manager_id'] = employees['manager_id'].astype('str')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:58:53.069293Z",
     "start_time": "2023-11-05T21:58:52.413808Z"
    }
   },
   "id": "ec7ea053ef68e41f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   employee_id       name manager_id  salary\n0            3       Mila          9   60301\n1           12  Antonella       <NA>   31000\n2           13      Emery       <NA>   67084\n3            1      Kalel         11   21241\n4            9    Mikaela       <NA>   50937\n5           11     Joziah          6   28485",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>employee_id</th>\n      <th>name</th>\n      <th>manager_id</th>\n      <th>salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Mila</td>\n      <td>9</td>\n      <td>60301</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>Antonella</td>\n      <td>&lt;NA&gt;</td>\n      <td>31000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>Emery</td>\n      <td>&lt;NA&gt;</td>\n      <td>67084</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>Kalel</td>\n      <td>11</td>\n      <td>21241</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>Mikaela</td>\n      <td>&lt;NA&gt;</td>\n      <td>50937</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>11</td>\n      <td>Joziah</td>\n      <td>6</td>\n      <td>28485</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employees"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:58:53.082289500Z",
     "start_time": "2023-11-05T21:58:53.069293Z"
    }
   },
   "id": "f66c8ae0bf799007"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 14:49:36 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 14:49:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 14:49:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+----------+------+\n",
      "|employee_id|     name|manager_id|salary|\n",
      "+-----------+---------+----------+------+\n",
      "|          3|     Mila|         9| 60301|\n",
      "|         12|Antonella|      null| 31000|\n",
      "|         13|    Emery|      null| 67084|\n",
      "|          1|    Kalel|        11| 21241|\n",
      "|          9|  Mikaela|      null| 50937|\n",
      "|         11|   Joziah|         6| 28485|\n",
      "+-----------+---------+----------+------+\n"
     ]
    }
   ],
   "source": [
    "#pyspark schema\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "employees_df = spark.createDataFrame(employees)\n",
    "employees_df.withColumn('manager_id', F.col('manager_id').cast('int')).show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:59:04.372488700Z",
     "start_time": "2023-11-05T21:58:53.078457Z"
    }
   },
   "id": "e9923c93f0905ded"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- manager_id: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "employees_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:59:04.372488700Z",
     "start_time": "2023-11-05T21:59:04.365732600Z"
    }
   },
   "id": "5f11d6030ab763af"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=================(16 + 0) / 16][Stage 4:>                (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|employee_id|\n",
      "+-----------+\n",
      "|         11|\n",
      "+-----------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Solving in pyspark dataframe\n",
    "\n",
    "employees_df \\\n",
    "    .filter(F.col('salary') < 30000) \\\n",
    "    .join(employees_df.alias('b').select('employee_id'), on=F.col('b.employee_id') == F.col('manager_id'), how='anti') \\\n",
    "    .select('employee_id') \\\n",
    "    .orderBy('employee_id') \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:59:07.054194300Z",
     "start_time": "2023-11-05T21:59:04.375017500Z"
    }
   },
   "id": "c8b400cd7b2c7b29"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|employee_id|\n",
      "+-----------+\n",
      "|         11|\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "# another way\n",
    "\n",
    "employee_list = employees_df.select('employee_id').rdd.map(lambda x: x[0]).collect()\n",
    "\n",
    "employees_df \\\n",
    "    .filter((F.col('salary') < 30000) & (~F.col('manager_id').isin(employee_list))) \\\n",
    "    .select('employee_id') \\\n",
    "    .orderBy('employee_id') \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:59:08.422303400Z",
     "start_time": "2023-11-05T21:59:07.045957500Z"
    }
   },
   "id": "f2b2b65805f17365"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|employee_id|\n",
      "+-----------+\n",
      "|         11|\n",
      "+-----------+\n"
     ]
    }
   ],
   "source": [
    "# In Spark SQL\n",
    "\n",
    "employees_df.createOrReplaceTempView('employees')\n",
    "\n",
    "spark.sql('''\n",
    "select employee_id\n",
    "from employees\n",
    "where salary<30000 and not manager_id in (select distinct employee_id from employees)\n",
    "order by employee_id;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T21:59:09.870875400Z",
     "start_time": "2023-11-05T21:59:08.413569200Z"
    }
   },
   "id": "221f2bff34ef738a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T22:06:19.945210200Z",
     "start_time": "2023-11-05T22:06:19.092076300Z"
    }
   },
   "id": "3166fcb1b24febff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da6a98599ef99d82"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
