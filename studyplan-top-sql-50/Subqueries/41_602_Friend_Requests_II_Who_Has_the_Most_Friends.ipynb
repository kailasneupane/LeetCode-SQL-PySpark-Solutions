{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [602. Friend Requests II: Who Has the Most Friends](https://leetcode.com/problems/friend-requests-ii-who-has-the-most-friends/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "879cbffec3fa2fab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: RequestAccepted\n",
    "\n",
    "<pre>+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| requester_id   | int     |\n",
    "| accepter_id    | int     |\n",
    "| accept_date    | date    |\n",
    "+----------------+---------+</pre>\n",
    "(requester_id, accepter_id) is the primary key (combination of columns with unique values) for this table.\n",
    "This table contains the ID of the user who sent the request, the ID of the user who received the request, and the date when the request was accepted.\n",
    " \n",
    "\n",
    "Write a solution to find the people who have the most friends and the most friends number.\n",
    "\n",
    "The test cases are generated so that only one person has the most friends.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "RequestAccepted table:\n",
    "<pre>+--------------+-------------+-------------+\n",
    "| requester_id | accepter_id | accept_date |\n",
    "+--------------+-------------+-------------+\n",
    "| 1            | 2           | 2016/06/03  |\n",
    "| 1            | 3           | 2016/06/08  |\n",
    "| 2            | 3           | 2016/06/08  |\n",
    "| 3            | 4           | 2016/06/09  |\n",
    "+--------------+-------------+-------------+</pre>\n",
    "Output: \n",
    "<pre>+----+-----+\n",
    "| id | num |\n",
    "+----+-----+\n",
    "| 3  | 3   |\n",
    "+----+-----+</pre>\n",
    "Explanation: \n",
    "The person with id 3 is a friend of people 1, 2, and 4, so he has three friends in total, which is the most number than any others.\n",
    " \n",
    "\n",
    "Follow up: In the real world, multiple people could have the same most number of friends. Could you find all these people in this case?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d512da3634975673"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 2, '2016/06/03'], [1, 3, '2016/06/08'], [2, 3, '2016/06/08'], [3, 4, '2016/06/09']]\n",
    "request_accepted = pd.DataFrame(data, columns=['requester_id', 'accepter_id', 'accept_date']).astype(\n",
    "    {'requester_id': 'Int64', 'accepter_id': 'Int64', 'accept_date': 'datetime64[ns]'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:27.983126900Z",
     "start_time": "2023-11-07T05:00:27.232916800Z"
    }
   },
   "id": "f437f40a6e593e02"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/06 17:04:43 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/06 17:04:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/06 17:04:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+-------------------+\n",
      "|requester_id|accepter_id|        accept_date|\n",
      "+------------+-----------+-------------------+\n",
      "|           1|          2|2016-06-03 00:00:00|\n",
      "|           1|          3|2016-06-08 00:00:00|\n",
      "|           2|          3|2016-06-08 00:00:00|\n",
      "|           3|          4|2016-06-09 00:00:00|\n",
      "+------------+-----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "#to spark dataframe\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "request_accepted_df = spark.createDataFrame(request_accepted)\n",
    "request_accepted_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:46.978769500Z",
     "start_time": "2023-11-07T05:00:27.990560500Z"
    }
   },
   "id": "a748c326cdacafb1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|friends|\n",
      "+---+-------+\n",
      "|  1|      2|\n",
      "|  2|      1|\n",
      "|  3|      1|\n",
      "+---+-------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# solving in spark df\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "requester_count_df = request_accepted_df\\\n",
    "    .groupBy(F.col('requester_id').alias('id'))\\\n",
    "    .agg(F.count('requester_id').alias('friends'))\n",
    "requester_count_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:49.120148300Z",
     "start_time": "2023-11-07T05:00:46.978769500Z"
    }
   },
   "id": "c90feaf205aedcdb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|friends|\n",
      "+---+-------+\n",
      "|  2|      1|\n",
      "|  3|      2|\n",
      "|  4|      1|\n",
      "+---+-------+\n"
     ]
    }
   ],
   "source": [
    "accepter_count_df = request_accepted_df\\\n",
    "    .groupBy(F.col('accepter_id').alias('id'))\\\n",
    "    .agg(F.count('accepter_id').alias('friends'))\n",
    "accepter_count_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:50.012288200Z",
     "start_time": "2023-11-07T05:00:49.126514600Z"
    }
   },
   "id": "332ed0659e010ff0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|friends|\n",
      "+---+-------+\n",
      "|  1|      2|\n",
      "|  3|      3|\n",
      "|  2|      2|\n",
      "|  4|      1|\n",
      "+---+-------+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "id_friends_df = requester_count_df\\\n",
    "    .unionAll(accepter_count_df)\\\n",
    "    .groupBy('id')\\\n",
    "    .agg(F.sum(F.col('friends')).alias('friends'))\n",
    "id_friends_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:51.514958800Z",
     "start_time": "2023-11-07T05:00:50.012288200Z"
    }
   },
   "id": "5eeeb4493428d1e6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:===>                                                    (1 + 15) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|num|\n",
      "+---+---+\n",
      "|  3|  3|\n",
      "+---+---+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "max_friend_df = id_friends_df.select('friends').agg(F.max('friends'))\n",
    "max_friends_value = max_friend_df.collect()[0][0]\n",
    "\n",
    "# this solution will work for the 'follow up' scenario mentioned on description\n",
    "final_df = id_friends_df.filter(F.col('friends')==max_friends_value)\\\n",
    "    .select('id',F.col('friends').alias('num'))\n",
    "final_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:53.984457400Z",
     "start_time": "2023-11-07T05:00:51.514958800Z"
    }
   },
   "id": "452e316fcc8b36fb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:==========================================>             (12 + 4) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|num|\n",
      "+---+---+\n",
      "|  3|  3|\n",
      "+---+---+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Solving in Spark SQL\n",
    "\n",
    "request_accepted_df.createOrReplaceTempView('RequestAccepted')\n",
    "\n",
    "spark.sql('''\n",
    "with id_friends as (\n",
    "select id, sum(friends) as friends from\n",
    "(   \n",
    "select requester_id as id, count(requester_id) as friends \n",
    "from requestaccepted group by requester_id\n",
    "    union all\n",
    "select accepter_id as id, count(accepter_id) as friends\n",
    "from requestaccepted group by accepter_id\n",
    ") tbl\n",
    "group by id\n",
    ")\n",
    "select id, friends as num\n",
    "from id_friends \n",
    "where (select max(friends) from id_friends) = friends;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:55.723686100Z",
     "start_time": "2023-11-07T05:00:53.992170500Z"
    }
   },
   "id": "adf1fa22f99b89a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T05:00:56.636468700Z",
     "start_time": "2023-11-07T05:00:55.731052700Z"
    }
   },
   "id": "c4b0810229d55a57"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
