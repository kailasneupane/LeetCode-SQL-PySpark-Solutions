{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1174. Immediate Food Delivery II](https://leetcode.com/problems/immediate-food-delivery-ii/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e292de6c1f170354"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Delivery\n",
    "\n",
    "<pre>+-----------------------------+---------+\n",
    "| Column Name                 | Type    |\n",
    "+-----------------------------+---------+\n",
    "| delivery_id                 | int     |\n",
    "| customer_id                 | int     |\n",
    "| order_date                  | date    |\n",
    "| customer_pref_delivery_date | date    |\n",
    "+-----------------------------+---------+</pre>\n",
    "delivery_id is the column of unique values of this table.\n",
    "The table holds information about food delivery to customers that make orders at some date and specify a preferred delivery date (on the same order date or after it).\n",
    " \n",
    "\n",
    "If the customer's preferred delivery date is the same as the order date, then the order is called immediate; otherwise, it is called scheduled.\n",
    "\n",
    "The first order of a customer is the order with the earliest order date that the customer made. It is guaranteed that a customer has precisely one first order.\n",
    "\n",
    "Write a solution to find the percentage of immediate orders in the first orders of all customers, rounded to 2 decimal places.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Delivery table:\n",
    "<pre>+-------------+-------------+------------+-----------------------------+\n",
    "| delivery_id | customer_id | order_date | customer_pref_delivery_date |\n",
    "+-------------+-------------+------------+-----------------------------+\n",
    "| 1           | 1           | 2019-08-01 | 2019-08-02                  |\n",
    "| 2           | 2           | 2019-08-02 | 2019-08-02                  |\n",
    "| 3           | 1           | 2019-08-11 | 2019-08-12                  |\n",
    "| 4           | 3           | 2019-08-24 | 2019-08-24                  |\n",
    "| 5           | 3           | 2019-08-21 | 2019-08-22                  |\n",
    "| 6           | 2           | 2019-08-11 | 2019-08-13                  |\n",
    "| 7           | 4           | 2019-08-09 | 2019-08-09                  |\n",
    "+-------------+-------------+------------+-----------------------------+</pre>\n",
    "Output: \n",
    "<pre>+----------------------+\n",
    "| immediate_percentage |\n",
    "+----------------------+\n",
    "| 50.00                |\n",
    "+----------------------+</pre>\n",
    "Explanation: \n",
    "The customer id 1 has a first order with delivery id 1 and it is scheduled.\n",
    "The customer id 2 has a first order with delivery id 2 and it is immediate.\n",
    "The customer id 3 has a first order with delivery id 5 and it is scheduled.\n",
    "The customer id 4 has a first order with delivery id 7 and it is immediate.\n",
    "Hence, half the customers have immediate first orders."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d8ab7732de1ce56"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#Pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 1, '2019-08-01', '2019-08-02'], [2, 2, '2019-08-02', '2019-08-02'], [3, 1, '2019-08-11', '2019-08-12'],\n",
    "        [4, 3, '2019-08-24', '2019-08-24'], [5, 3, '2019-08-21', '2019-08-22'], [6, 2, '2019-08-11', '2019-08-13'],\n",
    "        [7, 4, '2019-08-09', '2019-08-09']]\n",
    "delivery = pd.DataFrame(data,\n",
    "                        columns=['delivery_id', 'customer_id', 'order_date', 'customer_pref_delivery_date']).astype(\n",
    "    {'delivery_id': 'Int64', 'customer_id': 'Int64', 'order_date': 'datetime64[ns]',\n",
    "     'customer_pref_delivery_date': 'datetime64[ns]'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:14:06.221746300Z",
     "start_time": "2023-11-10T04:14:05.604069500Z"
    }
   },
   "id": "7687794ac6894141"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/09 15:01:31 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/09 15:01:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/09 15:01:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-------------------+---------------------------+\n",
      "|delivery_id|customer_id|order_date         |customer_pref_delivery_date|\n",
      "+-----------+-----------+-------------------+---------------------------+\n",
      "|1          |1          |2019-08-01 00:00:00|2019-08-02 00:00:00        |\n",
      "|2          |2          |2019-08-02 00:00:00|2019-08-02 00:00:00        |\n",
      "|3          |1          |2019-08-11 00:00:00|2019-08-12 00:00:00        |\n",
      "|4          |3          |2019-08-24 00:00:00|2019-08-24 00:00:00        |\n",
      "|5          |3          |2019-08-21 00:00:00|2019-08-22 00:00:00        |\n",
      "|6          |2          |2019-08-11 00:00:00|2019-08-13 00:00:00        |\n",
      "|7          |4          |2019-08-09 00:00:00|2019-08-09 00:00:00        |\n",
      "+-----------+-----------+-------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "# to spark dataframe\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "delivery_df = spark.createDataFrame(delivery)\n",
    "delivery_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:14:18.480710100Z",
     "start_time": "2023-11-10T04:14:06.192027500Z"
    }
   },
   "id": "6cd80696526e7b77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|immediate_percentage|\n",
      "+--------------------+\n",
      "|                50.0|\n",
      "+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# solving in spark dataframe\n",
    "from pyspark.sql import Window\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "delivery_df \\\n",
    "    .withColumn('rn', F.row_number().over(Window.partitionBy('customer_id').orderBy('order_date'))) \\\n",
    "    .filter(F.col('rn') == 1) \\\n",
    "    .agg(\n",
    "    F.round(100*\n",
    "        F.sum(F.when(F.col('order_date') == F.col('customer_pref_delivery_date'), 1).otherwise(0)) / F.count('*'),\n",
    "        2) \\\n",
    "        .alias('immediate_percentage')\n",
    ") \\\n",
    "    .show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:14:20.275561500Z",
     "start_time": "2023-11-10T04:14:18.480710100Z"
    }
   },
   "id": "186ed4ef44b89e8b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|immediate_percentage|\n",
      "+--------------------+\n",
      "|                50.0|\n",
      "+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# solving in spark SQL\n",
    "\n",
    "delivery_df.createOrReplaceTempView('delivery')\n",
    "\n",
    "spark.sql('''\n",
    "with tbl as (\n",
    "select *, row_number() over (partition by customer_id order by order_date) as rn\n",
    "from delivery\n",
    ")\n",
    "select \n",
    "    round(\n",
    "    100*sum(case when order_date=customer_pref_delivery_date then 1 else 0 end)/count(*),\n",
    "    2) as immediate_percentage\n",
    "from tbl\n",
    "where rn = 1;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:14:21.626829300Z",
     "start_time": "2023-11-10T04:14:20.274557700Z"
    }
   },
   "id": "4f8e0e85e7459224"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T04:14:22.365747800Z",
     "start_time": "2023-11-10T04:14:21.625560600Z"
    }
   },
   "id": "d304f639fecbaeca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
