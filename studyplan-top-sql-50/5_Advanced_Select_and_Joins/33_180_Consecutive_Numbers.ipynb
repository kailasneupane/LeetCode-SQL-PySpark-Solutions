{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [180. Consecutive Numbers](https://leetcode.com/problems/consecutive-numbers/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a245850859ae372"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Logs\n",
    "\n",
    "<pre>+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| id          | int     |\n",
    "| num         | varchar |\n",
    "+-------------+---------+</pre>\n",
    "In SQL, id is the primary key for this table.\n",
    "id is an autoincrement column.\n",
    " \n",
    "\n",
    "Find all numbers that appear at least three times consecutively.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Logs table:\n",
    "<pre>+----+-----+\n",
    "| id | num |\n",
    "+----+-----+\n",
    "| 1  | 1   |\n",
    "| 2  | 1   |\n",
    "| 3  | 1   |\n",
    "| 4  | 2   |\n",
    "| 5  | 1   |\n",
    "| 6  | 2   |\n",
    "| 7  | 2   |\n",
    "+----+-----+</pre>\n",
    "Output: \n",
    "<pre>+-----------------+\n",
    "| ConsecutiveNums |\n",
    "+-----------------+\n",
    "| 1               |\n",
    "+-----------------+</pre>\n",
    "Explanation: 1 is the only number that appears consecutively for at least three times."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "572a25466afbec94"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "#pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 1], [2, 1], [3, 1], [4, 2], [5, 1], [6, 2], [7, 2]]\n",
    "logs = pd.DataFrame(data, columns=['id', 'num']).astype({'id':'Int64', 'num':'Int64'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:21:56.379467600Z",
     "start_time": "2023-11-05T19:21:55.701484400Z"
    }
   },
   "id": "22cfc6b399b0dcb6"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:27:12 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:27:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:27:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|id |num|\n",
      "+---+---+\n",
      "|1  |1  |\n",
      "|2  |1  |\n",
      "|3  |1  |\n",
      "|4  |2  |\n",
      "|5  |1  |\n",
      "|6  |2  |\n",
      "|7  |2  |\n",
      "+---+---+\n"
     ]
    }
   ],
   "source": [
    "# to spark schema\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "logs_df = spark.createDataFrame(logs)\n",
    "logs_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:22:13.241664300Z",
     "start_time": "2023-11-05T19:21:56.389467200Z"
    }
   },
   "id": "4e00eb4aa7c62213"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/05 12:27:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:28 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:29 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ConsecutiveNums|\n",
      "+---------------+\n",
      "|              1|\n",
      "+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# in Spark Dataframe\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "logs_df.\\\n",
    "    withColumn('leadd',F.lead('num').over(Window.orderBy('id'))).\\\n",
    "    withColumn('lagg',F.lag('num').over(Window.orderBy('id'))).\\\n",
    "    filter((F.col('leadd')==F.col('lagg')) & (F.col('lagg')==F.col('num'))).\\\n",
    "    select(F.col('num').alias('ConsecutiveNums')).show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:22:15.973805600Z",
     "start_time": "2023-11-05T19:22:13.234751800Z"
    }
   },
   "id": "9c647b45dc8ee9da"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/05 12:27:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/11/05 12:27:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ConsecutiveNums|\n",
      "+---------------+\n",
      "|              1|\n",
      "+---------------+\n"
     ]
    }
   ],
   "source": [
    "# in Spark SQL\n",
    "logs_df.createOrReplaceTempView('logs')\n",
    "spark.sql('''\n",
    "select distinct num as ConsecutiveNums from \n",
    "(select id,num,lead(num) over (order by id) as leadd,lag(num) over (order by id) as lagg from logs) l\n",
    "where num=leadd and num=lagg;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:22:17.453451300Z",
     "start_time": "2023-11-05T19:22:15.964435400Z"
    }
   },
   "id": "fbe69d8b8cc3845"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:22:18.384506300Z",
     "start_time": "2023-11-05T19:22:17.444484700Z"
    }
   },
   "id": "3b09d0d3e7837236"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:22:18.447330300Z",
     "start_time": "2023-11-05T19:22:18.368172100Z"
    }
   },
   "id": "506b18216e655306"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
