{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1164. Product Price at a Given Date](https://leetcode.com/problems/product-price-at-a-given-date/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31ae3b6c6405b34a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Products\n",
    "\n",
    "<pre>+---------------+---------+\n",
    "| Column Name   | Type    |\n",
    "+---------------+---------+\n",
    "| product_id    | int     |\n",
    "| new_price     | int     |\n",
    "| change_date   | date    |\n",
    "+---------------+---------+</pre>\n",
    "(product_id, change_date) is the primary key (combination of columns with unique values) of this table.\n",
    "Each row of this table indicates that the price of some product was changed to a new price at some date.\n",
    " \n",
    "\n",
    "Write a solution to find the prices of all products on 2019-08-16. Assume the price of all products before any change is 10.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Products table:\n",
    "<pre>+------------+-----------+-------------+\n",
    "| product_id | new_price | change_date |\n",
    "+------------+-----------+-------------+\n",
    "| 1          | 20        | 2019-08-14  |\n",
    "| 2          | 50        | 2019-08-14  |\n",
    "| 1          | 30        | 2019-08-15  |\n",
    "| 1          | 35        | 2019-08-16  |\n",
    "| 2          | 65        | 2019-08-17  |\n",
    "| 3          | 20        | 2019-08-18  |\n",
    "+------------+-----------+-------------+</pre>\n",
    "Output: \n",
    "<pre>+------------+-------+\n",
    "| product_id | price |\n",
    "+------------+-------+\n",
    "| 2          | 50    |\n",
    "| 1          | 35    |\n",
    "| 3          | 10    |\n",
    "+------------+-------+</pre>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e815efdad737e725"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas Schema\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 20, '2019-08-14'], [2, 50, '2019-08-14'], [1, 30, '2019-08-15'], [1, 35, '2019-08-16'],\n",
    "        [2, 65, '2019-08-17'], [3, 20, '2019-08-18']]\n",
    "\n",
    "# data = [ #test case 4 from leet code\n",
    "#     [1, 20, '2019-08-17'],\n",
    "#     [2, 50, '2019-08-18'],\n",
    "#     [1, 30, '2019-08-15'],\n",
    "#     [1, 35, '2019-08-16'],\n",
    "#     [2, 65, '2019-08-17'],\n",
    "#     [3, 20, '2019-08-18']\n",
    "# ]\n",
    "\n",
    "products = pd.DataFrame(data, columns=['product_id', 'new_price', 'change_date']).astype(\n",
    "    {'product_id': 'Int64', 'new_price': 'Int64', 'change_date': 'datetime64[ns]'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:23:47.711631400Z",
     "start_time": "2023-11-05T19:23:47.056220Z"
    }
   },
   "id": "2cc89de269d42dfb"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 12:29:12 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 12:29:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 12:29:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------------------+\n",
      "|product_id|new_price|change_date        |\n",
      "+----------+---------+-------------------+\n",
      "|1         |20       |2019-08-14 00:00:00|\n",
      "|2         |50       |2019-08-14 00:00:00|\n",
      "|1         |30       |2019-08-15 00:00:00|\n",
      "|1         |35       |2019-08-16 00:00:00|\n",
      "|2         |65       |2019-08-17 00:00:00|\n",
      "|3         |20       |2019-08-18 00:00:00|\n",
      "+----------+---------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# to spark schema\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "products_df = spark.createDataFrame(products)\n",
    "products_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:06.649364800Z",
     "start_time": "2023-11-05T19:23:47.720086100Z"
    }
   },
   "id": "293090431e5bbe7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=========================>                                (7 + 9) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|price|\n",
      "+----------+-----+\n",
      "|         1|   35|\n",
      "+----------+-----+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# In spark dataframe\n",
    "\n",
    "#only records which has change_date = 2019-08-16\n",
    "pdf1 = products_df.filter(F.col('change_date')=='2019-08-16').select('product_id',F.col('new_price').alias('price')).distinct()\n",
    "pdf1.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:09.068662200Z",
     "start_time": "2023-11-05T19:24:06.648474700Z"
    }
   },
   "id": "f997c3f158165df7"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|price|\n",
      "+----------+-----+\n",
      "|         2|   50|\n",
      "+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "#only records which has only change_date < 2019-08-16\n",
    "pdf2 = products_df.join(pdf1, on=['product_id'], how = 'anti')\\\n",
    "    .filter((F.col('change_date')<'2019-08-16'))\\\n",
    "    .withColumn('flag',F.row_number().over(Window.partitionBy('product_id').orderBy(F.col('change_date').desc())))\\\n",
    "    .filter((F.col('flag')==1))\\\n",
    "    .select('product_id',F.col('new_price').alias('price')).distinct()\n",
    "pdf2.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:11.599440300Z",
     "start_time": "2023-11-05T19:24:09.069776700Z"
    }
   },
   "id": "6c17deaac7a2c63a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|price|\n",
      "+----------+-----+\n",
      "|         3|   10|\n",
      "+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "#only records which has only change_date > 2019-08-16\n",
    "pdf3 = products_df.join(pdf1, on=['product_id'], how = 'anti')\\\n",
    "    .join(pdf2, on=['product_id'], how = 'anti')\\\n",
    "    .withColumn('new_price',F.lit(10))\\\n",
    "    .select('product_id',F.col('new_price').alias('price')).distinct()\n",
    "pdf3.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:13.769365600Z",
     "start_time": "2023-11-05T19:24:11.586323Z"
    }
   },
   "id": "3fdca046e99fe7c7"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|price|\n",
      "+----------+-----+\n",
      "|         1|   35|\n",
      "|         2|   50|\n",
      "|         3|   10|\n",
      "+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "#now combining all\n",
    "final_df = pdf1.unionAll(pdf2).unionAll(pdf3)\n",
    "final_df.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:16.597197Z",
     "start_time": "2023-11-05T19:24:13.760798Z"
    }
   },
   "id": "74f0c4cb7315fe45"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|product_id|price|\n",
      "+----------+-----+\n",
      "|         1|   35|\n",
      "|         2|   50|\n",
      "|         3|   10|\n",
      "+----------+-----+\n"
     ]
    }
   ],
   "source": [
    "# In spark SQL\n",
    "\n",
    "products_df.createOrReplaceTempView('products')\n",
    "\n",
    "spark.sql('''\n",
    "with pdf1 as (\n",
    "-- #only records which has change_date = 2019-08-16\n",
    "    select distinct product_id, new_price as price \n",
    "    from products\n",
    "    where change_date = '2019-08-16'\n",
    "), pdf2 as (\n",
    "-- #only records which has only change_date < 2019-08-16\n",
    "    select product_id, new_price as price\n",
    "    from (\n",
    "        select distinct\n",
    "            products.product_id, products.new_price, products.change_date, \n",
    "            row_number() over (partition by products.product_id order by products.change_date desc) as cc\n",
    "        from products\n",
    "        left join pdf1\n",
    "        on pdf1.product_id = products.product_id\n",
    "        where change_date<'2019-08-16' and pdf1.product_id is null\n",
    "    ) p1 where p1.cc = 1\n",
    "), pdf3 as (\n",
    "-- #only records which has only change_date > 2019-08-16\n",
    "    select distinct products.product_id, 10 as price\n",
    "    from products\n",
    "    left join pdf1\n",
    "    on pdf1.product_id = products.product_id\n",
    "    left join pdf2\n",
    "    on pdf2.product_id = products.product_id\n",
    "    where pdf1.product_id is null and pdf2.product_id is null\n",
    ")\n",
    "select * from pdf1\n",
    "union all\n",
    "select * from pdf2\n",
    "union all\n",
    "select * from pdf3;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:19.556895Z",
     "start_time": "2023-11-05T19:24:16.593417Z"
    }
   },
   "id": "b05a2345639009cc"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T19:24:20.462979900Z",
     "start_time": "2023-11-05T19:24:19.550090500Z"
    }
   },
   "id": "55e04ccfc562fbf2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
