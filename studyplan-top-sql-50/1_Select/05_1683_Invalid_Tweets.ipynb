{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1683. Invalid Tweets](https://leetcode.com/problems/invalid-tweets/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c11e42ce944e8b6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table: Tweets\n",
    "<pre>\n",
    "+----------------+---------+\n",
    "| Column Name    | Type    |\n",
    "+----------------+---------+\n",
    "| tweet_id       | int     |\n",
    "| content        | varchar |\n",
    "+----------------+---------+</pre>\n",
    "tweet_id is the primary key (column with unique values) for this table.\n",
    "This table contains all the tweets in a social media app.\n",
    " \n",
    "\n",
    "Write a solution to find the IDs of the invalid tweets. The tweet is invalid if the number of characters used in the content of the tweet is strictly greater than 15.\n",
    "\n",
    "Return the result table in any order.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Tweets table:\n",
    "<pre>\n",
    "+----------+----------------------------------+\n",
    "| tweet_id | content                          |\n",
    "+----------+----------------------------------+\n",
    "| 1        | Vote for Biden                   |\n",
    "| 2        | Let us make America great again! |\n",
    "+----------+----------------------------------+</pre>\n",
    "Output: \n",
    "<pre>\n",
    "+----------+\n",
    "| tweet_id |\n",
    "+----------+\n",
    "| 2        |\n",
    "+----------+</pre>\n",
    "Explanation: \n",
    "Tweet 1 has length = 14. It is a valid tweet.\n",
    "Tweet 2 has length = 32. It is an invalid tweet."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca980b1a046feed2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# Pandas Schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [[1, 'Vote for Biden'], [2, 'Let us make America great again!']]\n",
    "tweets = pd.DataFrame(data, columns=['tweet_id', 'content']).astype({'tweet_id':'Int64', 'content':'object'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:09.155665200Z",
     "start_time": "2023-11-05T16:42:08.520003700Z"
    }
   },
   "id": "7ae06ec7a30f432f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/05 10:42:11 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/05 10:42:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 10:42:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# pyspark schema\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "tweets_df = spark.createDataFrame(tweets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:20.852728500Z",
     "start_time": "2023-11-05T16:42:09.162055800Z"
    }
   },
   "id": "14a2d9616b23d1fc"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- content: string (nullable = true)\n"
     ]
    }
   ],
   "source": [
    "tweets_df.printSchema()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:20.949914Z",
     "start_time": "2023-11-05T16:42:20.864804700Z"
    }
   },
   "id": "6d484e205f8b18df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------+\n",
      "|tweet_id|content                         |\n",
      "+--------+--------------------------------+\n",
      "|1       |Vote for Biden                  |\n",
      "|2       |Let us make America great again!|\n",
      "+--------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "tweets_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:25.108150Z",
     "start_time": "2023-11-05T16:42:20.934968400Z"
    }
   },
   "id": "ae647be0b9177562"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|tweet_id|\n",
      "+--------+\n",
      "|       2|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "# In spark Dataframe\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "tweets_df.filter(F.length(F.col('content'))>15).select('tweet_id').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:26.213153800Z",
     "start_time": "2023-11-05T16:42:25.105800200Z"
    }
   },
   "id": "55e5640ffe64dbb6"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|tweet_id|\n",
      "+--------+\n",
      "|       2|\n",
      "+--------+\n"
     ]
    }
   ],
   "source": [
    "#In spark SQL\n",
    "tweets_df.createOrReplaceTempView('tweets')\n",
    "\n",
    "spark.sql('''\n",
    "select tweet_id from tweets where length(content)>15;\n",
    "''').show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:27.330822Z",
     "start_time": "2023-11-05T16:42:26.199310700Z"
    }
   },
   "id": "aa5e6325b40ca733"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:28.320401700Z",
     "start_time": "2023-11-05T16:42:27.320450700Z"
    }
   },
   "id": "4dad55b0fe283b5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-05T16:42:28.372928100Z",
     "start_time": "2023-11-05T16:42:28.319402Z"
    }
   },
   "id": "8e6c943eb2db662a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
