{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# [1484. Group Sold Products By The Date](https://leetcode.com/problems/group-sold-products-by-the-date/description/?envType=study-plan-v2&envId=top-sql-50)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e247413c542f02d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Table Activities:\n",
    "\n",
    "<pre>+-------------+---------+\n",
    "| Column Name | Type    |\n",
    "+-------------+---------+\n",
    "| sell_date   | date    |\n",
    "| product     | varchar |\n",
    "+-------------+---------+</pre>\n",
    "There is no primary key (column with unique values) for this table. It may contain duplicates.\n",
    "Each row of this table contains the product name and the date it was sold in a market.\n",
    " \n",
    "\n",
    "Write a solution to find for each date the number of different products sold and their names.\n",
    "\n",
    "The sold products names for each date should be sorted lexicographically.\n",
    "\n",
    "Return the result table ordered by sell_date.\n",
    "\n",
    "The result format is in the following example.\n",
    "\n",
    " \n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input: \n",
    "Activities table:\n",
    "<pre>+------------+------------+\n",
    "| sell_date  | product     |\n",
    "+------------+------------+\n",
    "| 2020-05-30 | Headphone  |\n",
    "| 2020-06-01 | Pencil     |\n",
    "| 2020-06-02 | Mask       |\n",
    "| 2020-05-30 | Basketball |\n",
    "| 2020-06-01 | Bible      |\n",
    "| 2020-06-02 | Mask       |\n",
    "| 2020-05-30 | T-Shirt    |\n",
    "+------------+------------+</pre>\n",
    "Output: \n",
    "<pre>+------------+----------+------------------------------+\n",
    "| sell_date  | num_sold | products                     |\n",
    "+------------+----------+------------------------------+\n",
    "| 2020-05-30 | 3        | Basketball,Headphone,T-shirt |\n",
    "| 2020-06-01 | 2        | Bible,Pencil                 |\n",
    "| 2020-06-02 | 1        | Mask                         |\n",
    "+------------+----------+------------------------------+</pre>\n",
    "Explanation: \n",
    "For 2020-05-30, Sold items were (Headphone, Basketball, T-shirt), we sort them lexicographically and separate them by a comma.\n",
    "For 2020-06-01, Sold items were (Pencil, Bible), we sort them lexicographically and separate them by a comma.\n",
    "For 2020-06-02, the Sold item is (Mask), we just return it."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "233dfe95daff28d5"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# pandas schema\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [['2020-05-30', 'Headphone'], ['2020-06-01', 'Pencil'], ['2020-06-02', 'Mask'], ['2020-05-30', 'Basketball'],\n",
    "        ['2020-06-01', 'Bible'], ['2020-06-02', 'Mask'], ['2020-05-30', 'T-Shirt']]\n",
    "activities = pd.DataFrame(data, columns=['sell_date', 'product']).astype(\n",
    "    {'sell_date': 'datetime64[ns]', 'product': 'object'})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:08.238618400Z",
     "start_time": "2023-11-12T03:49:07.943123Z"
    }
   },
   "id": "71fbb3c195148094"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "bash: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8)\n",
      "23/11/11 21:27:08 WARN Utils: Your hostname, svchost resolves to a loopback address: 127.0.1.1; using 172.18.28.34 instead (on interface eth0)\n",
      "23/11/11 21:27:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/11 21:27:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|sell_date          |product   |\n",
      "+-------------------+----------+\n",
      "|2020-05-30 00:00:00|Headphone |\n",
      "|2020-06-01 00:00:00|Pencil    |\n",
      "|2020-06-02 00:00:00|Mask      |\n",
      "|2020-05-30 00:00:00|Basketball|\n",
      "|2020-06-01 00:00:00|Bible     |\n",
      "|2020-06-02 00:00:00|Mask      |\n",
      "|2020-05-30 00:00:00|T-Shirt   |\n",
      "+-------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#pyspark schema\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "activities_df = spark.createDataFrame(activities)\n",
    "activities_df.show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:17.549989900Z",
     "start_time": "2023-11-12T03:49:08.242746500Z"
    }
   },
   "id": "467e870e48036451"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                        (0 + 16) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------------------------------+\n",
      "|sell_date          |num_sold|products                        |\n",
      "+-------------------+--------+--------------------------------+\n",
      "|2020-05-30 00:00:00|3       |[Basketball, Headphone, T-Shirt]|\n",
      "|2020-06-01 00:00:00|2       |[Bible, Pencil]                 |\n",
      "|2020-06-02 00:00:00|1       |[Mask]                          |\n",
      "+-------------------+--------+--------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# solving in spark dataframe\n",
    "\n",
    "activities_df \\\n",
    "    .groupBy('sell_date') \\\n",
    "    .agg(\n",
    "    F.count_distinct('product').alias('num_sold'),\n",
    "    F.sort_array(F.collect_set(F.col('product'))).alias('products')\n",
    "    ) \\\n",
    "    .orderBy('sell_date') \\\n",
    "    .show(truncate=False)\n",
    "\n",
    "#to get rid of those brackets, we can use F.concat_ws(',',F.col()) but its type will be converted to string."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:19.212366400Z",
     "start_time": "2023-11-12T03:49:17.545337300Z"
    }
   },
   "id": "e318a5ca8fb7a065"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------+--------------------------------+\n",
      "|sell_date          |num_sold|products                        |\n",
      "+-------------------+--------+--------------------------------+\n",
      "|2020-05-30 00:00:00|3       |[Basketball, Headphone, T-Shirt]|\n",
      "|2020-06-01 00:00:00|2       |[Bible, Pencil]                 |\n",
      "|2020-06-02 00:00:00|1       |[Mask]                          |\n",
      "+-------------------+--------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# solving in spark SQL\n",
    "\n",
    "activities_df.createOrReplaceTempView('activities')\n",
    "\n",
    "spark.sql('''\n",
    "select \n",
    "    sell_date,\n",
    "    count(distinct product) as num_sold,\n",
    "    sort_array(collect_set(product)) as products\n",
    "from activities\n",
    "group by sell_date\n",
    "order by sell_date;\n",
    "''').show(truncate=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:19.927638500Z",
     "start_time": "2023-11-12T03:49:19.197983600Z"
    }
   },
   "id": "e1991fc0cc1e3254"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nselect \\n    sell_date,\\n    count(distinct product) as num_sold,\\n    group_concat(distinct product order by product asc) as products\\nfrom activities\\ngroup by sell_date\\norder by sell_date;\\n'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MySQL equivalent:\n",
    "\n",
    "'''\n",
    "select \n",
    "    sell_date,\n",
    "    count(distinct product) as num_sold,\n",
    "    group_concat(distinct product order by product asc) as products\n",
    "from activities\n",
    "group by sell_date\n",
    "order by sell_date;\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:19.928647100Z",
     "start_time": "2023-11-12T03:49:19.923561100Z"
    }
   },
   "id": "ab3dbbd5f9c646a0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T03:49:20.878472600Z",
     "start_time": "2023-11-12T03:49:19.927638500Z"
    }
   },
   "id": "b59447bc24994409"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
